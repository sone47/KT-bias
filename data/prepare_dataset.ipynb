{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduData import get_data\n",
    "import os\n",
    "\n",
    "dataset_dir = '2009_skill_builder_data_corrected'\n",
    "dataset_filename = 'skill_builder_data_corrected.csv'\n",
    "dataset_path = './' + dataset_dir + '/' + dataset_filename\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    get_data('assistment-2009-2010-skill', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\n",
    "    dataset_path,\n",
    "    usecols=['order_id', 'user_id', 'sequence_id', 'skill_id', 'correct']\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skills: 124\n"
     ]
    }
   ],
   "source": [
    "raw_question = data.skill_id.unique().tolist()\n",
    "num_skill = len(raw_question)\n",
    "\n",
    "def question_id_transfer(question):\n",
    "    id2question = [p for p in raw_question]\n",
    "    question2id = {}\n",
    "    for i, p in enumerate(raw_question):\n",
    "        question2id[p] = i\n",
    "\n",
    "    return id2question, question2id\n",
    "\n",
    "\n",
    "id2question, question2id = question_id_transfer(raw_question)\n",
    "\n",
    "print(\"number of skills: %d\" % num_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parse student sequence:\t: 100%|██████████| 4217/4217 [00:58<00:00, 71.94it/s] \n"
     ]
    }
   ],
   "source": [
    "def parse_all_seq(students):\n",
    "    all_sequences = []\n",
    "    for student_id in tqdm.tqdm(students, 'parse student sequence:\\t'):\n",
    "        student_sequence = parse_student_seq(data[data.user_id == student_id])\n",
    "        all_sequences.extend(student_sequence)\n",
    "    return all_sequences\n",
    "\n",
    "\n",
    "def parse_student_seq(student):\n",
    "    student = student.drop_duplicates(subset='order_id')\n",
    "    sequence_ids = student.sequence_id.unique()\n",
    "    sequences = []\n",
    "    for seq_id in sequence_ids:\n",
    "        seq = student[student.sequence_id == seq_id].sort_values('order_id')\n",
    "        questions = [question2id[id] for id in seq.skill_id.tolist()]\n",
    "        answers = seq.correct.tolist()\n",
    "        sequences.append((questions, answers))\n",
    "    return sequences\n",
    "\n",
    "\n",
    "# [(question_sequence_0, answer_sequence_0), ..., (question_sequence_n, answer_sequence_n)]\n",
    "sequences = parse_all_seq(data.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size=.7, shuffle=True):\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "    boundary = round(len(data) * train_size)\n",
    "    return data[: boundary], data[boundary:]\n",
    "\n",
    "\n",
    "train_sequences, test_sequences = train_test_split(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences2tl(sequences, trgpath):\n",
    "    with open(trgpath, 'a', encoding='utf8') as f:\n",
    "        for seq in tqdm.tqdm(sequences, 'write into file: '):\n",
    "            questions, answers = seq\n",
    "            seq_len = len(questions)\n",
    "            f.write(str(seq_len) + '\\n')\n",
    "            f.write(','.join([str(q) for q in questions]) + '\\n')\n",
    "            f.write(','.join([str(a) for a in answers]) + '\\n')\n",
    "\n",
    "\n",
    "# save triple line format for other tasks\n",
    "train_data_path = './' + dataset_dir + '/train.txt'\n",
    "test_data_path = './' + dataset_dir + '/test.txt'\n",
    "if not os.path.exists(train_data_path):\n",
    "    sequences2tl(train_sequences, train_data_path)\n",
    "if not os.path.exists(test_data_path):\n",
    "    sequences2tl(test_sequences, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert to onehot format:   5%|▌         | 2172/41912 [02:43<49:55, 13.26it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-d2cea0f4a238>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;31m# save onehot data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_onehot_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m     \u001B[0mtrain_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencode_onehot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_sequences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMAX_STEP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNUM_QUESTIONS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_onehot_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_onehot_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-d2cea0f4a238>\u001B[0m in \u001B[0;36mencode_onehot\u001B[0;34m(sequences, max_step, num_questions)\u001B[0m\n\u001B[1;32m     25\u001B[0m                 \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq_seq\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0ma_seqs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mq_seq\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mnum_questions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m                 \u001B[0monehot\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m             \u001B[0monehot_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0monehot_result\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0monehot\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0monehot_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mnum_questions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mappend\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/Desktop/graduate/KT-bias/venv/lib/python3.9/site-packages/numpy/lib/function_base.py\u001B[0m in \u001B[0;36mappend\u001B[0;34m(arr, values, axis)\u001B[0m\n\u001B[1;32m   4743\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4744\u001B[0m         \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4745\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4746\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4747\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# one-hot\n",
    "\n",
    "MAX_STEP = 50\n",
    "NUM_QUESTIONS = num_skill\n",
    "\n",
    "\n",
    "def encode_one_hot(sequences, max_step, num_questions):\n",
    "    question_sequences = np.array([])\n",
    "    answer_sequences = np.array([])\n",
    "    one_hot_result = []\n",
    "\n",
    "    for questions, answers in tqdm.tqdm(sequences, 'convert to one-hot format: '):\n",
    "        length = len(questions)\n",
    "        # append questions' and answers' length to an integer multiple of max_step\n",
    "        mod = 0 if length % max_step == 0 else (max_step - length % max_step)\n",
    "        fill_content = np.zeros(mod) - 1\n",
    "        questions = np.append(questions, fill_content)\n",
    "        answers = np.append(answers, fill_content)\n",
    "        # one hot\n",
    "        q_seqs = questions.reshape([-1, max_step])\n",
    "        a_seqs = answers.reshape([-1, max_step])\n",
    "        for (i, q_seq) in enumerate(q_seqs):\n",
    "            one_hot = np.zeros(shape = [max_step, 2 * num_questions])\n",
    "            for j in range(max_step):\n",
    "                index = int(q_seq[j] if a_seqs[i][j] > 0 else q_seq[j] + num_questions)\n",
    "                one_hot[j][index] = 1\n",
    "            one_hot_result = np.append(one_hot_result, one_hot)\n",
    "    \n",
    "    return one_hot_result.reshape(-1, max_step, 2 * num_questions)\n",
    "\n",
    "\n",
    "train_one_hot_path = './' + dataset_dir + '/train_data.npy'\n",
    "test_one_hot_path = './' + dataset_dir + '/test_data.npy'\n",
    "\n",
    "# save one_hot data\n",
    "if not os.path.exists(train_one_hot_path):\n",
    "    train_data = encode_one_hot(train_sequences, MAX_STEP, NUM_QUESTIONS)\n",
    "    np.save(train_one_hot_path, train_data)\n",
    "if not os.path.exists(test_one_hot_path):\n",
    "    test_data = encode_one_hot(test_sequences, MAX_STEP, NUM_QUESTIONS)\n",
    "    np.save(test_one_hot_path, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}